{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the recon-all pipeline (Freesurfer).\n",
    "The output is written to the 'outdir' listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THESE VARIABLES\n",
    "analysis_version = \"2017_12_12\"\n",
    "project_dir = Path('/data/NNDSP/') # needs to be pathlib.Path object\n",
    "ncpus = '8'\n",
    "ram = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freesurfer_dir  = project_dir.joinpath('anal/freesurfer_files_john/other_files')\n",
    "expert_opts = freesurfer_dir.joinpath('expert.opts')\n",
    "conf_script = freesurfer_dir.joinpath('conf' + analysis_version + '.sh')\n",
    "# subj_dir = project_dir.joinpath('derivatives') # passed using the conf script though\n",
    "subj_dir =  project_dir / 'derivatives' / 'fs_subj_john'\n",
    "bids_dir = Path('./bids_2017_07_14')\n",
    "log_dir = freesurfer_dir.joinpath('swarm_output', analysis_version)\n",
    "\n",
    "swarm_path = freesurfer_dir.joinpath('cross_sectional_recon_' + analysis_version + '.cmd')\n",
    "\n",
    "\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the values here, they must be edited\n",
    "conf_script.write_text(\"\"\"\n",
    "umask 0007\n",
    "export base=/data/NNDSP\n",
    "export SUBJECTS_DIR=$base/derivatives/fs_subj_john\n",
    "module load freesurfer fsl afni \n",
    "source ${FREESURFER_HOME}/SetUpFreeSurfer.sh\n",
    "export PATH=$base/scripts:/data/DSST/scripts/:${PATH}\n",
    "alias csf=\"mkdir -p .trash;mv -f cmd.* swarm*[eo] sw*n*.[eo] .trash/\"\n",
    "ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating subject list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans = pd.DataFrame(columns=['scan_path'],data=[p.as_posix() for p in bids_dir.glob('**/*T1w.nii.gz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scans = df_scans.assign(subject = lambda df: df.scan_path.str.extract('(sub-\\d{2,4})', expand=True))\n",
    "df_scans = pd.concat(\n",
    "    [df_scans,\n",
    "     df_scans.scan_path.\n",
    "     str.extract(\n",
    "         '.*(?P<subject>sub-\\d{2,4}).*(?P<run>run-[0-9]{3}).*',\n",
    "         expand=True)],\n",
    "    axis = 1)\n",
    "\n",
    "df_scans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running recon-all on all scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_freesurfer_command(tpNid=None,subj_dir=None,ncpus='4',image=None,conf_script=None,  data_on_lscratch=False):\n",
    "        # (cross sectional):  recon-all -all -s <tpNid> -i path_to_tpN_dcm\n",
    "    lscratch = Path('/lscratch/$SLURM_JOBID/work')\n",
    "    oic = lscratch.joinpath('out')\n",
    "    cmd = 'mkdir -p ' + oic.as_posix() + ';'\n",
    "    cmd += 'source ' + conf_script.as_posix() + ';' + \\\n",
    "    ' recon-all' +  \\\n",
    "    ' -all' + \\\n",
    "    ' -no-isrunning' + \\\n",
    "    ' -sd ' + oic.as_posix() + \\\n",
    "    ' -openmp ' + ncpus + \\\n",
    "    ' -s ' + tpNid + \\\n",
    "    ' -i ' + image \n",
    "    \n",
    "    cmd += '; rsync -a {lscratch}/out/ '.format(lscratch = lscratch.as_posix()) + subj_dir.absolute().as_posix() + '/;'  \n",
    "    cmd += ' rm -rf /lscratch/$SLURM_JOB_ID/*'\n",
    "\n",
    "    return cmd\n",
    "# generate_singularity_command(output_dir=output_dir, sing_image= sing_image, bids_dir=bids_dir, participant=participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cross-sectional reconall commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sing = (\n",
    "    df_scans.\n",
    "    assign(\n",
    "        cmd = lambda df:\n",
    "        generate_freesurfer_command(tpNid = df.subject + '_' + df.run,\n",
    "                                    subj_dir = subj_dir,\n",
    "                                    conf_script = conf_script,\n",
    "                                    image = df.scan_path,\n",
    "                                    ncpus = ncpus))\n",
    "          )\n",
    "\n",
    "swarm_path = freesurfer_dir.joinpath('cross_sectional_recon_' + analysis_version + '.cmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_path.write_text('\\n'.join(df_sing.cmd.drop_duplicates())) \n",
    "\n",
    "swarm_path.read_text().splitlines()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df_sing.cmd),len(df_sing.cmd.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = !swarm -f {swarm_path} -g {ram} -t {ncpus} --logdir {log_dir} --time 24:00:00 --partition=nimh,norm --gres=lscratch:200\n",
    "job_id = job_id[0]\n",
    "job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exploring possible issues with swarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_of_interest = []\n",
    "# df_error_files_paths = pd.DataFrame([x.as_posix() for x in Path('swarm_output_2017_06_05').glob('*.e')],columns=['paths'])\n",
    "df_error_files_paths = pd.DataFrame([x.as_posix() for x in log_dir.glob('*.e')],columns=['paths'])\n",
    "df_error_files = (df_error_files_paths.\n",
    "                  assign(run = lambda df:\n",
    "                         df.paths.str.extract(\n",
    "                             '/.*swarm_\\d*_(\\d*).e',\n",
    "                             expand=False).\n",
    "                         astype(int)).sort_values('run'))\n",
    "if not files_of_interest:\n",
    "    files_of_interest = list(range(len(df_error_files_paths)))\n",
    "\n",
    "\n",
    "df_error_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files failed (observed on dashboard):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(np.array(df_error_files.paths)[[164,119,113,95,14,15]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_files = [Path(x).read_text() for x in np.array(df_error_files.paths)[[164,119,113,95,14,15]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = [Path(x).with_suffix('.o').read_text() for x in np.array(df_error_files.paths)[[164,119,113,95,14,15]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(output_files))b\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
