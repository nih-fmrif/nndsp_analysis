{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_version = \"2017_10_19\"\n",
    "project_dir = Path('/Users/rodgersleejg/data/hpc/NNDSP') # needs to be pathlib.Path object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = project_dir.joinpath('bids_2017_07_14')\n",
    "\n",
    "mriqc_dir  = project_dir.joinpath('anal/mriqc_files/other_files')\n",
    "if not mriqc_dir.exists():\n",
    "    mriqc_dir.mkdir()\n",
    "output_folder =  project_dir / 'derivatives' / 'mriqc'\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "\n",
    "log_dir = mriqc_dir.joinpath('swarm_output_' +  analysis_version)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "manual_qc = output_folder.joinpath('manual_qc_metrics.csv')\n",
    "second_round_mprage_ratings = mriqc_dir.joinpath('ohbm_2018','mprage_multi_scans.csv')\n",
    "out_qc = manual_qc.with_name('manual_qc_round_2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = pd.read_csv(manual_qc)\n",
    "difficult_col1 = [c for c in df_manual.columns if c.find('Freesurfer_int')==0 and c.find('discrep')>0][0]\n",
    "difficult_col2 = 'Freesurfer_avg_int_rating '\n",
    "df_manual = (df_manual.\n",
    "             rename(columns = \n",
    "                    {\n",
    "                        difficult_col1 : 'Freesurfer_int_discrepency',\n",
    "                        difficult_col2 : 'Freesurfer_avg_int_rating'\n",
    "                    }\n",
    "                    \n",
    "                   )\n",
    "            )\n",
    "df_manual['MASKID'] = df_manual.MASKID.apply(lambda x: '{n:04d}'.format(n = x))\n",
    "df_manual['run'] = '001'\n",
    "df_manual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addition = pd.read_csv(second_round_mprage_ratings).rename(columns = {'Mask ID':'MASKID'})\n",
    "df_addition['MASKID'] = df_addition.MASKID.apply(lambda x: '{n:04d}'.format(n = x))\n",
    "df_addition['Notes'] = df_addition.Notes.str.replace('(\\d/\\d/2014)','date')\n",
    "df_addition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_1 = ['first','1st','1/','1 of','3TA']\n",
    "patterns_2 = ['second','2nd','2/','2 of','3TB']\n",
    "patterns_3 = ['third','3rd','3/','3 of','reliability']\n",
    "patterns_4 = ['fourth','4th','4/','4 of']\n",
    "p1 = '.*' + '.*|.*'.join(patterns_1) + '.*'\n",
    "p2 = '.*' + '.*|.*'.join(patterns_2) + '.*'\n",
    "p3 = '.*' + '.*|.*'.join(patterns_3) + '.*'\n",
    "p4 = '.*' + '.*|.*'.join(patterns_4) + '.*'\n",
    "\n",
    "\n",
    "df_addition.loc[ df_addition.Notes.str.contains(p1,regex=True), 'run'] = '001'\n",
    "df_addition.loc[ df_addition.Notes.str.contains(p2,regex=True), 'run'] = '002'\n",
    "df_addition.loc[ df_addition.Notes.str.contains(p3,regex=True), 'run'] = '003'\n",
    "df_addition.loc[ df_addition.Notes.str.contains(p4,regex=True), 'run'] = '004'\n",
    "df_addition.loc[df_addition.run.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addition.loc[ df_addition.Notes.str.contains('.*3TB.*',regex=True), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_ids = df_addition.MASKID.unique()\n",
    "addition_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_kept = ['MASKID', 'nuclear_fam_id', 'Sex', 'age_at_scan']\n",
    "df_matching = (df_manual.\n",
    "               loc[[iii in addition_ids for iii in df_manual.MASKID],cols_kept].\n",
    "               merge(df_addition.drop('Scanner', axis =1).rename(columns = {'QC':'MPRAGE'}),\n",
    "                     on = 'MASKID',\n",
    "                     indicator = True).\n",
    "               drop('_merge',axis = 1)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_matching is df_manual and df_addition merged. Need to remove these ids from df_manual and then merge back into that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (df_manual.\n",
    "           loc[[iii not in addition_ids for iii in df_manual.MASKID],:].\n",
    "           merge(df_matching,indicator = True,how = 'outer')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby('_merge').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_manual),len(df_addition),len(df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_full.query(\"_merge == 'both'\")) == 0\n",
    "print(len(df_full.query(\"_merge == 'both'\")))\n",
    "df_full = df_full.drop('_merge',axis = 1).sort_values(['MASKID','run']).reset_index(drop = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_full.to_csv(out_qc,sep = '\\t',index = False)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_qc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
