{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running previous notebook from mriqc_exploration:')\n",
    "%run '/Users/rodgersleejg/data/hpc/NNDSP/anal/mriqc_files/analysis_notebooks/merge_manual_qc_files.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THESE VARIABLES\n",
    "analysis_version = \"2017_10_19\"\n",
    "project_dir = Path('/Users/rodgersleejg/data/hpc/NNDSP') # needs to be pathlib.Path object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = project_dir.joinpath('bids_2017_07_14')\n",
    "\n",
    "# conf_script = mriqc_dir.joinpath('conf' + analysis_version + '.sh')\n",
    "\n",
    "mriqc_dir  = project_dir.joinpath('anal/mriqc_files/other_files')\n",
    "if not mriqc_dir.exists():\n",
    "    mriqc_dir.mkdir()\n",
    "output_folder =  project_dir / 'derivatives' / 'mriqc'\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "classifier_output =  output_folder.joinpath('classifier')\n",
    "if not classifier_output.exists():\n",
    "    classifier_output.mkdir()\n",
    "base_work_dir = output_folder.joinpath('work')\n",
    "if not base_work_dir.exists():\n",
    "    base_work_dir.mkdir()\n",
    "log_dir = mriqc_dir.joinpath('swarm_output_' +  analysis_version)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "manual_qc = output_folder.joinpath('manual_qc_round_2.tsv')\n",
    "# /Users/rodgersleejg/data/hpc/NNDSP/derivatives/mriqc/manual_qc_round_2.tsv\n",
    "# swarm_path = mriqc_dir.joinpath('mriqc_' + analysis_version + '.cmd')\n",
    "\n",
    "\n",
    "mriqc_with_predictions = Path('derivatives/mriqc/with_mriqc_predictions.csv')\n",
    "plottable_data = Path('derivatives/mriqc/classifer_plot_data.pklz')\n",
    "plottable_data_euler = Path('derivatives/mriqc/classifer_plot_data_euler.pklz')\n",
    "qc_data = Path('anal/mriqc_files/other_files/qc_pickle_for_v2_exploration.pklz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anal.python_modules.inner_merge_and_report as pd_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MRIQC on their data (DS030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of mriqc was downloaded more recently than the paper publication. Some of the IQMs  have changed but it is roughly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ghost included in test set:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "# export SINGULARITY_BINDPATH=\"/gpfs,/gs2,/gs3,/gs4,/gs5,/gs6,/gs7,/gs8,/spin1,/scratch,/fdb,/lscratch,/data\"; \\\n",
    "SINGULARITY_BINDPATH=\"\"\n",
    "SINGULARITY_IMAGES=/data/FMRIF/mriqc/images\n",
    "MRIQC_PATH=/usr/local/miniconda/lib/python3.6/site-packages/mriqc\n",
    "module load singularity\n",
    "singularity exec \\\n",
    "$SINGULARITY_IMAGES/poldracklab_mriqc_latest-2017-08-30-8b9b2e23f462.img \\\n",
    "mriqc_clf \\\n",
    "--load-classifier $MRIQC_PATH/data/mclf_run-20170724-191452_mod-rfc_ver-0.9.7-rc8_class-2_cv-loso_data-train_estimator.pklz \\\n",
    "--test $MRIQC_PATH/data/csv/x_ds030.csv \\\n",
    "$MRIQC_PATH/data/csv/y_ds030.csv \\\n",
    "--log-file -v --njobs 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ghost excluded in test set:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "# export SINGULARITY_BINDPATH=\"/gpfs,/gs2,/gs3,/gs4,/gs5,/gs6,/gs7,/gs8,/spin1,/scratch,/fdb,/lscratch,/data\"; \\\n",
    "SINGULARITY_BINDPATH=\"\"\n",
    "SINGULARITY_IMAGES=/data/FMRIF/mriqc/images\n",
    "MRIQC_PATH=/usr/local/miniconda/lib/python3.6/site-packages/mriqc\n",
    "module load singularity\n",
    "singularity exec \\\n",
    "$SINGULARITY_IMAGES/poldracklab_mriqc_latest-2017-08-30-8b9b2e23f462.img \\\n",
    "mriqc_clf \\\n",
    "--load-classifier $MRIQC_PATH/data/mclf_run-20170724-191452_mod-rfc_ver-0.9.7-rc8_class-2_cv-loso_data-train_estimator.pklz \\\n",
    "--test $MRIQC_PATH/data/csv/x_ds030.csv \\\n",
    "$MRIQC_PATH/data/csv/y_ds030_noghost.csv \\\n",
    "--log-file -v --njobs 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For NNDSP data get mriqc classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file = Path('derivatives/mriqc/x_nndsp.csv')\n",
    "if not feature_file.exists():\n",
    "    df_example = pd.read_csv('/home/rodgersleejg/x_ds030.csv')\n",
    "    cols = df_example.columns\n",
    "    cols = [cols[0],'run_id',*cols[1:]]\n",
    "    t1 = pd.read_csv('derivatives/mriqc/T1w.csv')\n",
    "    t1.loc[:,cols].to_csv(feature_file,index = False)\n",
    "\n",
    "else:\n",
    "    t1 = pd.read_csv(feature_file)\n",
    "\n",
    "# t1.loc[:,cols].loc[t1.subject_id == 1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "cd /data/NNDSP/derivatives/mriqc/classifier\n",
    "export SINGULARITY_BINDPATH=\"/gpfs,/gs2,/gs3,/gs4,/gs5,/gs6,/gs7,/gs8,/spin1,/scratch,/fdb,/lscratch,/data\"; \\\n",
    "SINGULARITY_IMAGES=/data/FMRIF/mriqc/images\n",
    "MRIQC_PATH=/usr/local/miniconda/lib/python3.6/site-packages/mriqc\n",
    "module load singularity\n",
    "singularity exec \\\n",
    "$SINGULARITY_IMAGES/poldracklab_mriqc_latest-2017-08-30-8b9b2e23f462.img \\\n",
    "mriqc_clf \\\n",
    "--load-classifier $MRIQC_PATH/data/mclf_run-20170724-191452_mod-rfc_ver-0.9.7-rc8_class-2_cv-loso_data-train_estimator.pklz \\\n",
    "-X /data/NNDSP/derivatives/mriqc/x_nndsp.csv \\\n",
    "--log-file -v --njobs 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {classifier_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pd_custom)\n",
    "if mriqc_with_predictions.exists():\n",
    "    df_mriqc = pd.read_csv('derivatives/mriqc/with_mriqc_predictions.csv')\n",
    "else:\n",
    "    df_pred = pd.read_csv(classifier_output.joinpath('mclf_run-20171027-140418_data-unseen_pred.csv'))\n",
    "    df_mriqc = pd_custom.merge_and_report(df_pred,t1, on = ['subject_id','run_id'])\n",
    "    df_mriqc.to_csv(mriqc_with_predictions,index = False)\n",
    "\n",
    "df_mriqc['run'] = df_mriqc.run_id.apply(lambda x: 'run-' + '{n:03d}'.format(n = x))\n",
    "df_mriqc.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with NNDSP manual qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out subjects with multiple scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some MASKIDs have multiple runs and it is unclear which scan the manual qc is referring to. So first I will get all the scans that don't have duplicate runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans = pd.DataFrame(columns=['scan_path'],data=[p.as_posix() for p in bids_dir.glob('**/anat/*T1w.nii.gz')])\n",
    "# df_scans = df_scans.assign(subject = lambda df: df.scan_path.str.extract('(sub-\\d{2,4})', expand=True))\n",
    "df_scans = pd.concat(\n",
    "    [df_scans,\n",
    "     df_scans.scan_path.\n",
    "     str.extract(\n",
    "         '.*(?P<subject>sub-\\d{2,4})/.*(?P<run>run-[a-zA-Z0-9]{1,8})_.*',\n",
    "         expand=True)],\n",
    "    axis = 1)\n",
    "df_scans['MASKID']  = df_scans.subject.str.replace('sub-','')\n",
    "\n",
    "print(len(df_scans))\n",
    "df_scans.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_scans.scan_path.nunique(), df_scans.subject.nunique(), df_scans.run.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans_filtered = df_scans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load manual qc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = pd.read_csv(manual_qc,sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult_col1 = [c for c in df_manual.columns if c.find('Freesurfer_int')==0 and c.find('discrep')>0][0]\n",
    "difficult_col2 = 'Freesurfer_avg_int_rating '\n",
    "df_manual = (df_manual.\n",
    "             rename(columns = \n",
    "                    {\n",
    "                        difficult_col1 : 'Freesurfer_int_discrepency',\n",
    "                        difficult_col2 : 'Freesurfer_avg_int_rating'\n",
    "                    }\n",
    "                    \n",
    "                   )\n",
    "            )\n",
    "df_manual['MASKID'] = df_manual.MASKID.apply(lambda x: '{n:04d}'.format(n = x))\n",
    "df_manual['run'] = df_manual.run.apply(lambda x: 'run-' + '{n:03d}'.format(n = x))\n",
    "print(len(df_manual))\n",
    "# df_manual.loc[df_manual.duplicated(['MASKID'],keep = False),:].sort_values('MASKID')\n",
    "# df_manual.loc[df_manual.duplicated(['MASKID','run'],keep = False),:].sort_values('MASKID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to manual qc and merge with scan paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num ratings: ', len(df_manual), ' Unique mask_ids: ', df_manual.MASKID.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_scans_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pd_custom)\n",
    "# df_qc = pd_custom.merge_and_report(df_manual, df_scans_filtered, on = ['MASKID'])\n",
    "df_qc = df_manual.merge(df_scans_filtered, on = ['MASKID','run'], how = 'outer',indicator = True)\n",
    "# there are tarred dicoms for the below files. they must have not been extracted by heudiconv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some manual ratings didn't have scans extracted for them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_qc.query(\"MASKID == '1360'\")\n",
    "df_qc.query(\"_merge != 'both'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc = df_qc.query(\"_merge == 'both'\").drop( '_merge', axis = 0, errors ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_qc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with mriqc values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mriqc = df_mriqc.query('run_id == 1')\n",
    "df_mriqc['MASKID'] = df_mriqc.subject_id.apply(lambda x: '{n:04d}'.format(n = x))\n",
    "\n",
    "df_qc_full = df_qc.copy().merge(df_mriqc,how = 'inner',on = ['MASKID','run'])\n",
    "print(len(df_mriqc), len(df_qc_full))\n",
    "df_qc_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_mriqc), len(df_qc_full),' File: ', qc_data)\n",
    "df_qc_full.to_pickle(qc_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
