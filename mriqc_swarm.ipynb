{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THESE VARIABLES\n",
    "analysis_version = \"2017_08_25\"\n",
    "project_dir = Path('/data/NNDSP') # needs to be pathlib.Path object\n",
    "ncpus = '10'\n",
    "ram = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = project_dir.joinpath('bids_2017_07_14')\n",
    "\n",
    "# conf_script = mriqc_dir.joinpath('conf' + analysis_version + '.sh')\n",
    "\n",
    "mriqc_dir  = project_dir.joinpath('anal/mriqc_files/other_files')\n",
    "if not mriqc_dir.exists():\n",
    "    mriqc_dir.mkdir()\n",
    "output_folder =  project_dir / 'derivatives' / 'mriqc'\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "base_work_dir = output_folder.joinpath('work')\n",
    "if not base_work_dir.exists():\n",
    "    base_work_dir.mkdir()\n",
    "log_dir = mriqc_dir.joinpath('swarm_output_' +  analysis_version)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "\n",
    "swarm_path = mriqc_dir.joinpath('mriqc_' + analysis_version + '.cmd')\n",
    "sing_image = Path('/data/FMRIF/mriqc/images/mriqc_parsing2.img')\n",
    "# sing_image = Path('/data/Hippo_hr/moa/anal/mriqc_files/other_files/poldracklab_mriqc-2017-07-26-9f304acebfe0.img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {output_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating subject list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans = pd.DataFrame(columns=['scan_path'],data=[p.as_posix() for p in bids_dir.glob('**/anat/*T1w.nii.gz')])\n",
    "# df_scans = df_scans.assign(subject = lambda df: df.scan_path.str.extract('(sub-\\d{2,4})', expand=True))\n",
    "df_scans = pd.concat(\n",
    "    [df_scans,\n",
    "     df_scans.scan_path.\n",
    "     str.extract(\n",
    "         '.*(?P<subject>sub-\\d{2,4})/.*(?P<run>run-[a-zA-Z0-9]{1,8})_.*',\n",
    "         expand=True)],\n",
    "    axis = 1)\n",
    "\n",
    "df_scans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running mriqc on all scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: mriqc [-h] [--version]\n",
    "#              [--participant_label PARTICIPANT_LABEL [PARTICIPANT_LABEL ...]]\n",
    "#              [--session-id SESSION_ID [SESSION_ID ...]]\n",
    "#              [--run-id RUN_ID [RUN_ID ...]] [--task-id TASK_ID [TASK_ID ...]]\n",
    "#              [-m [{T1w,bold,T2w} [{T1w,bold,T2w} ...]]] [-w WORK_DIR]\n",
    "#              [--report-dir REPORT_DIR] [--verbose-reports] [--write-graph]\n",
    "#              [--dry-run] [--profile] [--use-plugin USE_PLUGIN] [--no-sub]\n",
    "#              [--email EMAIL] [-v] [--webapi-url WEBAPI_URL]\n",
    "#              [--webapi-port WEBAPI_PORT] [--upload-strict] [--n_procs N_PROCS]\n",
    "#              [--mem_gb MEM_GB] [--testing] [-f] [--ica] [--hmc-afni]\n",
    "#              [--hmc-fsl] [--fft-spikes-detector] [--fd_thres FD_THRES]\n",
    "#              [--ants-nthreads ANTS_NTHREADS] [--ants-settings ANTS_SETTINGS]\n",
    "#              [--deoblique] [--despike] [--start-idx START_IDX]\n",
    "#              [--stop-idx STOP_IDX] [--correct-slice-timing]\n",
    "#              bids_dir output_dir {participant,group} [{participant,group} ...]\n",
    "\n",
    "def generate_mriqc_command(df_row,bids_root=None,output_folder=None,ncpus='4',ram='8',image=None):\n",
    "\n",
    "#     mriqc bids-root/ output-folder/ participant --participant-label S01 S02 S03\n",
    "    work_dir = output_folder.joinpath('work','_'.join([df_row.subject, df_row.run]))\n",
    "    report_dir = work_dir.joinpath('report')\n",
    "    cmd = 'module load singularity;' + \\\n",
    "    ' mkdir ' + work_dir.as_posix() + ';' + \\\n",
    "    ' mkdir ' + report_dir.as_posix() + ';' + \\\n",
    "    ' singularity exec ' + sing_image.as_posix() + \\\n",
    "    ' mriqc' +  \\\n",
    "    ' --run-id ' + df_row.run + \\\n",
    "    ' --ants-nthreads ' + ncpus + \\\n",
    "    ' --n_procs ' + ncpus + \\\n",
    "    ' --mem_gb ' + ram + \\\n",
    "    ' --email ' + 'johnleenimh@gmail.com' + \\\n",
    "    ' --verbose-reports' + \\\n",
    "    ' --write-graph' + \\\n",
    "    ' --report-dir ' + report_dir.as_posix() + \\\n",
    "    ' -w ' + work_dir.as_posix() + \\\n",
    "    ' ' + bids_root.as_posix() + \\\n",
    "    ' ' + output_folder.as_posix() + \\\n",
    "    ' participant' + \\\n",
    "    ' --participant-label ' + df_row.subject\n",
    "\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mriqc commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sing = df_scans.copy()\n",
    "df_sing['cmd'] = df_scans.apply(lambda df: generate_mriqc_command(df_row = df,\n",
    "                                                 bids_root = bids_dir,\n",
    "                                                 output_folder = output_folder,\n",
    "                                                 ncpus = ncpus,\n",
    "                                                 ram = ram,\n",
    "                                                 image = sing_image),\n",
    "              axis = 1)\n",
    "# sometimes not all commands resolve to a single scan so getting unique ones before writing swarm\n",
    "swarm_path.write_text('\\n'.join(df_sing.cmd.drop_duplicates())) \n",
    "# print(swarm_path.read_text())\n",
    "swarm_path.read_text().splitlines()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df_sing.cmd),len(df_sing.cmd.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = !swarm -f  {swarm_path} -g {ram} -t {ncpus} --logdir {log_dir} --time 96:00:00 --partition=nimh,norm\n",
    "job_id = job_id[0]\n",
    "job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "job_id for swarm that worked: 48276164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring potential issues with swarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_of_interest = []\n",
    "# df_error_files_paths = pd.DataFrame([x.as_posix() for x in Path('swarm_output_2017_06_05').glob('*.e')],columns=['paths'])\n",
    "df_error_files_paths = pd.DataFrame([x.as_posix() for x in log_dir.glob('*' + job_id + '*.e')],columns=['paths'])\n",
    "df_error_files = (df_error_files_paths.\n",
    "                  assign(run = lambda df:\n",
    "                         df.paths.str.extract(\n",
    "                             '/.*swarm_\\d*_(\\d*).e',\n",
    "                             expand=False).\n",
    "                         astype(int)).sort_values('run'))\n",
    "if not files_of_interest:\n",
    "    files_of_interest = list(range(len(df_error_files_paths)))\n",
    "\n",
    "\n",
    "df_error_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files failed (observed on dashboard):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(np.array(df_error_files.paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_files = [Path(x).read_text() for x in np.array(df_error_files.paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = [Path(x).with_suffix('.o').read_text() for x in np.array(df_error_files.paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n'.join(output_files[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {output_folder.joinpath('reports')}|wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing output of the mriqc swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = pd.DataFrame(columns=['file'],data=[p.as_posix() for p in output_folder.joinpath('reports').iterdir()])\n",
    "# df_scans = df_scans.assign(subject = lambda df: df.scan_path.str.extract('(sub-\\d{2,4})', expand=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = pd.concat(\n",
    "    [df_html,\n",
    "     df_html.file.\n",
    "     str.extract(\n",
    "         '.*(?P<subject>sub-\\d{2,4}).*(?P<run>run-[a-zA-Z0-9]{1,8})_.*',\n",
    "         expand=True)],\n",
    "    axis = 1)\n",
    "\n",
    "df_html.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load singularity; singularity exec {sing_image.as_posix()} mriqc --n_procs 5 --mem_gb 30 --email johnleenimh@gmail.com --verbose-reports --write-graph -w {base_work_dir.as_posix()} {bids_dir.as_posix()} {output_folder} group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {output_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w = pd.read_csv(output_folder.joinpath('T1w.csv'))\n",
    "\n",
    "t2w = pd.read_csv(output_folder.joinpath('T2w.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w['subject'] = t1w.subject_id.apply(lambda x: 'sub-{n:04d}'.format(n = x))\n",
    "t1w['run'] = t1w.run_id.apply(lambda x: 'run-{n:03d}'.format(n = x))\n",
    "# t1w.duplicated(['subject_id','run_id']).sum() # no duplicate subject/run combos\n",
    "df_qc = pd.merge(df_scans,t1w, on = ['subject','run'], how = 'outer', indicator= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc.query(\"_merge != 'both'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
