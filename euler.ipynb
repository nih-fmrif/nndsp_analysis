{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THESE VARIABLES\n",
    "analysis_version = \"2017_10_19\"\n",
    "project_dir = Path('/Users/rodgersleejg/data/hpc/NNDSP') # needs to be pathlib.Path object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = project_dir.joinpath('bids_2017_07_14')\n",
    "\n",
    "# conf_script = mriqc_dir.joinpath('conf' + analysis_version + '.sh')\n",
    "\n",
    "mriqc_dir  = project_dir.joinpath('anal/mriqc_files/other_files')\n",
    "if not mriqc_dir.exists():\n",
    "    mriqc_dir.mkdir()\n",
    "output_folder =  project_dir / 'derivatives' / 'mriqc'\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "classifier_output =  output_folder.joinpath('classifier')\n",
    "if not classifier_output.exists():\n",
    "    classifier_output.mkdir()\n",
    "base_work_dir = output_folder.joinpath('work')\n",
    "if not base_work_dir.exists():\n",
    "    base_work_dir.mkdir()\n",
    "log_dir = mriqc_dir.joinpath('swarm_output_' +  analysis_version)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "manual_qc = output_folder.joinpath('manual_qc_round_2.tsv')\n",
    "# swarm_path = mriqc_dir.joinpath('mriqc_' + analysis_version + '.cmd')\n",
    "\n",
    "\n",
    "df_qc_full_pkl = Path('anal/mriqc_files/other_files/qc_pickle_for_v2_exploration.pklz')\n",
    "mriqc_with_predictions = Path('derivatives/mriqc/with_mriqc_predictions.csv')\n",
    "plottable_data = Path('derivatives/mriqc/classifer_plot_data.pklz')\n",
    "plottable_data_euler = Path('derivatives/mriqc/classifer_plot_data_euler.pklz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anal.python_modules.inner_merge_and_report as pd_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc_full = pd.read_pickle(df_qc_full_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_qc_full.groupby(['MASKID','run']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Euler number for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_surface_holes(aseg_path):\n",
    "    pat = re.compile('.*holes in [lr]h surfaces prior to fixing, (\\d*).*')\n",
    "    vals = [int(x) for x in pat.findall(aseg_path.read_text())]\n",
    "    return vals\n",
    "def get_maskid_from_aseg_path(aseg_path):\n",
    "    pat = re.compile('.*sub-(?P<subject_num>\\d{2,4})_.*/.*/.*')\n",
    "    vals = [int(x) for x in pat.findall(aseg_path.as_posix())]\n",
    "    assert len(vals) ==1\n",
    "    sub_num = vals[0]\n",
    "    return '{n:04d}'.format(n=sub_num)\n",
    "\n",
    "def get_run_from_aseg_path(aseg_path):\n",
    "    pat = re.compile('.*sub-\\d{2,4}_run-(?P<run>\\d{2,4})/.*/.*')\n",
    "    vals = [int(x) for x in pat.findall(aseg_path.as_posix())]\n",
    "    assert len(vals) ==1\n",
    "    run = vals[0]\n",
    "    return 'run-' + '{n:03d}'.format(n=run)\n",
    "\n",
    "# aseg_path = Path('/data/NNDSP/derivatives/fs5.3_subj/sub-001/stats/aseg.stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aseg = pd.DataFrame({'aseg_path': list(Path('derivatives/fs_subj_john/').glob('sub*/stats/aseg.stats'))})\n",
    "df_aseg = (df_aseg.\n",
    "           assign(euler = lambda df: df.aseg_path.apply(get_lr_surface_holes)).\n",
    "           assign(mean_euler = lambda df: df.euler.apply(np.mean))\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aseg['MASKID'] = df_aseg.aseg_path.apply(get_maskid_from_aseg_path)\n",
    "df_aseg['run'] = df_aseg.aseg_path.apply(get_run_from_aseg_path)\n",
    "\n",
    "df_aseg = df_aseg.assign(subject = 'sub-' + df_aseg.MASKID)\n",
    "df_aseg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_aseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euler = df_qc_full.drop('_merge',axis = 1, errors = 'ignore').copy().merge(df_aseg, on = ['MASKID','run'],how = 'outer',indicator = True)\n",
    "df_euler._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euler = df_euler.query(\"_merge == 'both'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euler.head()['mean_euler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euler['prob_y'] = df_euler['mean_euler']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get performance metrics for the classifier (euler predicting manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anal.python_modules import classification\n",
    "reload(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb; ipdb=Pdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_metrics = ['Freesurfer_avg_ext_rating', 'Freesurfer_avg_int_rating', 'MPRAGE']\n",
    "classifier_metrics = ['tpr','fpr','fdr','fp','tp','fn','tn']\n",
    "for metric in manual_metrics:\n",
    "    col_prob = 'prob_y'\n",
    "    col_true = metric + '_thresholded'\n",
    "    threshold = 3\n",
    "    df_euler[col_true] = df_euler[metric] >= threshold\n",
    "    df_performance = classification.get_classification_scores(df_euler,col_true,col_prob)\n",
    "#     ipdb.runcall(classification.get_classification_scores,df_euler,col_true,col_prob)\n",
    "    df_euler.drop(df_performance.columns,axis = 1, inplace=True,errors='ignore')\n",
    "    df_euler = pd.concat([df_euler, df_performance],axis = 1)\n",
    "df_euler.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather value columns together using melt and create labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value cols need to all be the same type so that they can be melted to a single columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cols = df_euler.filter(regex = '^(Free|MP).*(' + 'thresholded' + ')').columns\n",
    "df_euler.loc[:,t_cols] = df_euler.loc[:,t_cols].apply(lambda col:col.astype(float),axis = 0)\n",
    "\n",
    "tail_of_regex = '|'.join(classifier_metrics) + '|thresholded'\n",
    "cols_regex = '^(Free|MP).*(' + tail_of_regex + ')'\n",
    "value_cols = df_euler.filter(regex= cols_regex, axis=1).columns\n",
    "ids_to_keep = pd.Index(['MASKID','run','prob_y', 'pred_y','threshold'])\n",
    "\n",
    "print('Regex for value columns to be melted,separated and pivoted: ', cols_regex)\n",
    "print('ids: ',ids_to_keep,'\\n\\n\\nvalues: ',value_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_euler.melt(id_vars = ids_to_keep,\n",
    "                var_name= 'binarized_manual_qc_scores',\n",
    "                            value_name= 'value',\n",
    "                value_vars= value_cols)\n",
    "df_melted = (\n",
    "    pd.concat(\n",
    "        [df_melted,\n",
    "        (df_melted.\n",
    "         binarized_manual_qc_scores.\n",
    "         str.\n",
    "         extract(expand=True,\n",
    "                 pat= '(?P<manual_qc_type>.*)_(?P<value_type>' + tail_of_regex  + ')')\n",
    "        )],\n",
    "    axis = 1)\n",
    ")\n",
    "df_melted = df_melted.loc[df_melted.MASKID.notnull(),:]\n",
    "len(df_melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column each for the tpr and fpr variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['MASKID','run', 'manual_qc_type','prob_y','pred_y','value_type']\n",
    "df_roc_euler = df_melted[[*cols,'value']].set_index(cols).unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_from_pivot = df_roc_euler.columns.levels[1][:-1]\n",
    "df_roc_euler.head()\n",
    "\n",
    "df_roc_euler.columns = [*cols[:-1], *cols_from_pivot]\n",
    "df_roc_euler['fpratio'] = df_roc_euler.fp/df_roc_euler.tp\n",
    "df_roc_euler['positive'] = df_roc_euler.fp + df_roc_euler.tp\n",
    "df_roc_euler.to_pickle(plottable_data_euler)\n",
    "df_roc_euler.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(df_roc_euler.query('manual_qc_type == \"MPRAGE\"')), plottable_data_euler))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
